{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\ntrain_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\ndf = train_transaction.merge(train_identity, on='TransactionID', how='left')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dagshub.init(repo_owner='gioeba', repo_name='IEEE-CIS-Fraud-Detection', mlflow=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"class FeatureEngineeringTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        START_DATE = pd.to_datetime('2017-12-01')\n        X['TransactionDT'] = pd.to_timedelta(X['TransactionDT'], unit='s')\n        X['datetime'] = START_DATE + X['TransactionDT']\n        X['hour'] = X['datetime'].dt.hour\n        X['weekday'] = X['datetime'].dt.weekday\n        X['day'] = X['datetime'].dt.day\n        X.drop(columns=['datetime'], inplace=True)\n\n        X['DeviceInfo'] = X['DeviceInfo'].fillna('unknown').str.lower()\n        X['device_os'] = X['DeviceInfo'].str.extract(r'([a-z]+)', expand=False)\n        X['device_ver'] = X['DeviceInfo'].str.extract(r'(\\d+)', expand=False)\n        \n        X = X.loc[:, X.isnull().mean() < 0.5].copy()\n\n        if 'card1' in X.columns and 'card2' in X.columns:\n            X['card1_card2_ratio'] = X['card1'] / (X['card2'] + 1)\n        if 'card1' in X.columns and 'addr1' in X.columns:\n            X['card1_addr1'] = X['card1'].astype(str) + '_' + X['addr1'].astype(str)\n        if 'card1' in X.columns and 'TransactionAmt' in X.columns:\n            X['card1_count'] = X.groupby('card1')['TransactionAmt'].transform('count')\n            X['card1_mean'] = X.groupby('card1')['TransactionAmt'].transform('mean')\n\n        return X\n\nfeature_engineering = FeatureEngineeringTransformer()\n\nmlflow.set_experiment(\"ieee-fe\")\nwith mlflow.start_run(run_name=\"fe-v2\"):\n    mlflow.sklearn.log_model(feature_engineering, \"feature_engineering\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"class DynamicPreprocessor(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.preprocessor = None\n\n    def fit(self, X, y=None):\n        cat_cols = X.select_dtypes('object').columns.tolist()\n        num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\n        num_transform = Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ])\n\n        cat_transform = Pipeline([\n            ('imputer', SimpleImputer(strategy='most_frequent')),\n            ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n        ])\n\n        self.preprocessor = ColumnTransformer([\n            ('num', num_transform, num_cols),\n            ('cat', cat_transform, cat_cols)\n        ])\n        self.preprocessor.fit(X)\n        return self\n\n    def transform(self, X):\n        return self.preprocessor.transform(X)\n\nmlflow.set_experiment(\"ieee-pre-processor\")\nwith mlflow.start_run(run_name=\"pre-processor-v2\"):\n    mlflow.sklearn.log_model(preprocessor, \"pre-processor\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}